{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "libcurand.so.10: cannot open shared object file: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5b08dff51592>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMNIST\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;31m# See Note [Global dependencies]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mUSE_GLOBAL_DEPS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0m_load_global_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m_load_global_deps\u001b[0;34m()\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0mlib_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlib_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m     \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlib_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRTLD_GLOBAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/ctypes/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: libcurand.so.10: cannot open shared object file: No such file or directory"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST\n",
    "import numpy as np\n",
    "import pygame\n",
    "import torch\n",
    "import os\n",
    "import detectron2\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "from detectron2.structures import BoxMode\n",
    "import cv2\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate bounding boxes for each digit in the dataset\n",
    "def calculate_bounding_boxes(images):\n",
    "    bounding_boxes = []\n",
    "    for img in images:\n",
    "        img_np = np.array(img)\n",
    "        rows = np.any(img_np, axis=1)\n",
    "        cols = np.any(img_np, axis=0)\n",
    "        ymin, ymax = np.where(rows)[0][[0, -1]]\n",
    "        xmin, xmax = np.where(cols)[0][[0, -1]]\n",
    "        bounding_boxes.append([xmin, ymin, xmax, ymax])\n",
    "    return bounding_boxes\n",
    "\n",
    "# Load MNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "mnist_train = MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "mnist_test = MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Calculate bounding boxes for the training and test datasets\n",
    "train_bboxes = calculate_bounding_boxes(mnist_train.data)\n",
    "test_bboxes = calculate_bounding_boxes(mnist_test.data)\n",
    "\n",
    "# Example to show bounding boxes\n",
    "print(train_bboxes[:5])\n",
    "print(test_bboxes[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mnist_dicts(images, bboxes, labels):\n",
    "    dataset_dicts = []\n",
    "    for idx, (img, bbox, label) in enumerate(zip(images, bboxes, labels)):\n",
    "        record = {}\n",
    "        \n",
    "        height, width = img.shape\n",
    "\n",
    "        record[\"file_name\"] = f\"{idx}.png\"\n",
    "        record[\"image_id\"] = idx\n",
    "        record[\"height\"] = height\n",
    "        record[\"width\"] = width\n",
    "        \n",
    "        obj = {\n",
    "            \"bbox\": bbox,\n",
    "            \"bbox_mode\": BoxMode.XYXY_ABS,\n",
    "            \"category_id\": label\n",
    "        }\n",
    "        \n",
    "        record[\"annotations\"] = [obj]\n",
    "        dataset_dicts.append(record)\n",
    "    return dataset_dicts\n",
    "\n",
    "# Register the dataset\n",
    "for d in [\"train\", \"test\"]:\n",
    "    DatasetCatalog.register(\"mnist_\" + d, lambda d=d: get_mnist_dicts(\n",
    "        mnist_train.data.numpy() if d == \"train\" else mnist_test.data.numpy(),\n",
    "        train_bboxes if d == \"train\" else test_bboxes,\n",
    "        mnist_train.targets.numpy() if d == \"train\" else mnist_test.targets.numpy()\n",
    "    ))\n",
    "    MetadataCatalog.get(\"mnist_\" + d).set(thing_classes=[str(i) for i in range(10)])\n",
    "\n",
    "# Configure the Detectron2 model\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"mnist_train\",)\n",
    "cfg.DATASETS.TEST = (\"mnist_test\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.00025  # pick a good LearningRate\n",
    "cfg.SOLVER.MAX_ITER = 300    # 300 iterations\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128  # faster, and good enough for this dataset (default: 512)\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 10  # 10 classes (digits 0-9)\n",
    "cfg.MODEL.DEVICE = \"cuda\"  # Use GPU for training\n",
    "\n",
    "# Train the model\n",
    "trainer = DefaultTrainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the trained model\n",
    "os.makedirs(\"model_output\", exist_ok=True)\n",
    "torch.save(trainer.model.state_dict(), \"model_output/mnist_digit_detector.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize PyGame\n",
    "pygame.init()\n",
    "\n",
    "# Set up the drawing window\n",
    "screen = pygame.display.set_mode([280, 280])\n",
    "pygame.display.set_caption('Draw a digit')\n",
    "\n",
    "# Set up the brush\n",
    "brush_size = 8\n",
    "brush_color = (255, 255, 255)\n",
    "\n",
    "# Run until the user asks to quit\n",
    "running = True\n",
    "drawing = False\n",
    "\n",
    "# Create a surface for drawing\n",
    "draw_surface = pygame.Surface((280, 280))\n",
    "draw_surface.fill((0, 0, 0))\n",
    "\n",
    "while running:\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT:\n",
    "            running = False\n",
    "        elif event.type == pygame.MOUSEBUTTONDOWN:\n",
    "            drawing = True\n",
    "        elif event.type == pygame.MOUSEBUTTONUP:\n",
    "            drawing = False\n",
    "        elif event.type == pygame.MOUSEMOTION:\n",
    "            if drawing:\n",
    "                pygame.draw.circle(draw_surface, brush_color, event.pos, brush_size)\n",
    "    \n",
    "    # Draw everything\n",
    "    screen.blit(draw_surface, (0, 0))\n",
    "    pygame.display.flip()\n",
    "\n",
    "# Save the drawing\n",
    "pygame.image.save(draw_surface, \"drawn_digit.png\")\n",
    "\n",
    "# Load and process the drawing\n",
    "image = cv2.imread(\"drawn_digit.png\", cv2.IMREAD_GRAYSCALE)\n",
    "image = cv2.resize(image, (28, 28), interpolation=cv2.INTER_AREA)\n",
    "image = 255 - image  # Invert colors\n",
    "image = image / 255.0  # Normalize\n",
    "\n",
    "# Predict the digit using the trained model\n",
    "model = trainer.model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    input_image = torch.tensor(image).unsqueeze(0).unsqueeze(0).float()  # Add batch and channel dimensions\n",
    "    predictions = model([{\"image\": input_image}])\n",
    "\n",
    "# Process and display predictions\n",
    "for prediction in predictions:\n",
    "    boxes = prediction[\"instances\"].pred_boxes.tensor.cpu().numpy()\n",
    "    scores = prediction[\"instances\"].scores.cpu().numpy()\n",
    "    classes = prediction[\"instances\"].pred_classes.cpu().numpy()\n",
    "\n",
    "    for box, score, cls in zip(boxes, scores, classes):\n",
    "        if score > 0.5:  # Consider only high confidence predictions\n",
    "            x1, y1, x2, y2 = box.astype(int)\n",
    "            cv2.rectangle(image, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "            cv2.putText(image, str(cls), (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "\n",
    "cv2.imshow('Predicted Digits', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Quit PyGame\n",
    "pygame.quit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
